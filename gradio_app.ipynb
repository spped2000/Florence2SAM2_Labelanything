{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d97729c0-e984-4b93-a160-087aff544272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://a877bb8acbfb705f13.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a877bb8acbfb705f13.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Public URL: <a href=\"https://a877bb8acbfb705f13.gradio.live\" target=\"_blank\">https://a877bb8acbfb705f13.gradio.live</a></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Flash Attention is disabled as it requires a GPU with Ampere (8.0) CUDA capability.\n",
      "2024-09-26 09:56:09.970249: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-26 09:56:10.015525: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-26 09:56:10.015562: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-26 09:56:10.015598: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-26 09:56:10.023075: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-26 09:56:10.931943: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: uploads/image_0.png\n",
      "Successfully saved annotated images as \"outputs/image_0_open_vocabulary_detection.jpg\" and \"outputs/image_0_open_vocabulary_detection_with_mask.jpg\"\n",
      "Successfully saved mask coordinates to \"outputs/image_0_mask.txt\"\n",
      "Successfully saved bounding box coordinates to \"outputs/image_0_box.txt\"\n",
      "Processing complete. All images saved to outputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Flash Attention is disabled as it requires a GPU with Ampere (8.0) CUDA capability.\n",
      "2024-09-26 09:58:00.741846: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-26 09:58:00.786937: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-26 09:58:00.786982: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-26 09:58:00.787012: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-26 09:58:00.794624: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-26 09:58:01.732368: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: uploads/image_0.png\n",
      "Successfully saved annotated images as \"outputs/image_0_open_vocabulary_detection.jpg\" and \"outputs/image_0_open_vocabulary_detection_with_mask.jpg\"\n",
      "Successfully saved mask coordinates to \"outputs/image_0_mask.txt\"\n",
      "Successfully saved bounding box coordinates to \"outputs/image_0_box.txt\"\n",
      "Processing image: uploads/image_1.png\n",
      "Successfully saved annotated images as \"outputs/image_1_open_vocabulary_detection.jpg\" and \"outputs/image_1_open_vocabulary_detection_with_mask.jpg\"\n",
      "Successfully saved mask coordinates to \"outputs/image_1_mask.txt\"\n",
      "Successfully saved bounding box coordinates to \"outputs/image_1_box.txt\"\n",
      "Processing image: uploads/image_2.png\n",
      "Successfully saved annotated images as \"outputs/image_2_open_vocabulary_detection.jpg\" and \"outputs/image_2_open_vocabulary_detection_with_mask.jpg\"\n",
      "Successfully saved mask coordinates to \"outputs/image_2_mask.txt\"\n",
      "Successfully saved bounding box coordinates to \"outputs/image_2_box.txt\"\n",
      "Processing complete. All images saved to outputs.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "import shutil\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "UPLOAD_FOLDER = 'uploads'\n",
    "OUTPUT_FOLDER = 'outputs'\n",
    "SAVE_FOLDER = 'saved_results'\n",
    "\n",
    "def process_images(images, text_input):\n",
    "    # Clear previous uploads and outputs\n",
    "    for folder in [UPLOAD_FOLDER, OUTPUT_FOLDER]:\n",
    "        if os.path.exists(folder):\n",
    "            shutil.rmtree(folder)\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    # Save uploaded images\n",
    "    image_paths = []\n",
    "    for i, image in enumerate(images):\n",
    "        file_extension = os.path.splitext(image.name)[1]\n",
    "        image_path = os.path.join(UPLOAD_FOLDER, f\"image_{i}{file_extension}\")\n",
    "        shutil.copy(image.name, image_path)\n",
    "        image_paths.append(image_path)\n",
    "    \n",
    "    # Run the auto-labeling script\n",
    "    cmd = [\n",
    "        'python', 's2f2_labelanything.py',\n",
    "        '--pipeline', 'open_vocabulary_detection_segmentation',\n",
    "        '--image_dir', UPLOAD_FOLDER,\n",
    "        '--output_dir', OUTPUT_FOLDER,\n",
    "        '--text_input', text_input\n",
    "    ]\n",
    "    subprocess.run(cmd)\n",
    "    \n",
    "    # Collect output files\n",
    "    output_files = glob.glob(os.path.join(OUTPUT_FOLDER, '*'))\n",
    "    \n",
    "    # Prepare results\n",
    "    image_results = []\n",
    "    box_coordinates = \"\"\n",
    "    for file in output_files:\n",
    "        if file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_results.append((file, os.path.basename(file)))\n",
    "        elif file.endswith('_box.txt'):\n",
    "            with open(file, 'r') as f:\n",
    "                content = f.read()\n",
    "            box_coordinates += f\"Bounding boxes for {os.path.basename(file)}:\\n{content}\\n\\n\"\n",
    "    \n",
    "    return image_results, box_coordinates\n",
    "\n",
    "def save_results(save_button, use_box_coordinates):\n",
    "    if not save_button:\n",
    "        return \"Click the Save button to save results.\"\n",
    "    \n",
    "    if not os.path.exists(SAVE_FOLDER):\n",
    "        os.makedirs(SAVE_FOLDER)\n",
    "    \n",
    "    # Copy original images\n",
    "    for image in glob.glob(os.path.join(UPLOAD_FOLDER, '*')):\n",
    "        shutil.copy(image, SAVE_FOLDER)\n",
    "    \n",
    "    # Copy label files based on user selection\n",
    "    label_type = \"box\" if use_box_coordinates else \"mask\"\n",
    "    for label_file in glob.glob(os.path.join(OUTPUT_FOLDER, f'*_{label_type}.txt')):\n",
    "        new_name = os.path.basename(label_file).replace(f'_{label_type}', '')\n",
    "        shutil.copy(label_file, os.path.join(SAVE_FOLDER, new_name))\n",
    "    \n",
    "    return f\"Results saved in {SAVE_FOLDER} folder with {'box' if use_box_coordinates else 'mask'} coordinates.\"\n",
    "\n",
    "with gr.Blocks() as iface:\n",
    "    gr.Markdown(\"# Auto-Label Image Processor\")\n",
    "    gr.Markdown(\"Upload images and provide text input for open vocabulary detection and segmentation.\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        input_images = gr.File(file_count=\"multiple\", label=\"Upload Images\")\n",
    "        text_input = gr.Textbox(label=\"Text Input (e.g., 'green basket')\")\n",
    "    \n",
    "    process_button = gr.Button(\"Process Images\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        output_gallery = gr.Gallery(label=\"Processed Images\", show_label=True)\n",
    "        output_text = gr.Textbox(label=\"Bounding Box Coordinates\", show_label=True)\n",
    "    \n",
    "    with gr.Row():\n",
    "        use_box_coordinates = gr.Checkbox(label=\"Use bounding box coordinates (uncheck for mask coordinates)\", value=True)\n",
    "        save_button = gr.Button(\"Save Results\")\n",
    "    \n",
    "    save_output = gr.Textbox(label=\"Save Status\")\n",
    "    \n",
    "    process_button.click(\n",
    "        process_images,\n",
    "        inputs=[input_images, text_input],\n",
    "        outputs=[output_gallery, output_text]\n",
    "    )\n",
    "    \n",
    "    save_button.click(\n",
    "        save_results,\n",
    "        inputs=[save_button, use_box_coordinates],\n",
    "        outputs=[save_output]\n",
    "    )\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch(share=True)\n",
    "\n",
    "# Display the public URL\n",
    "public_url = iface.share_url\n",
    "display(HTML(f'<p>Public URL: <a href=\"{public_url}\" target=\"_blank\">{public_url}</a></p>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b62a505-9f19-4ce1-8245-6022705e678a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
